{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m02pOSyHoj95",
    "outputId": "dfb371a9-ef41-4065-aa00-3c60a0168b78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58jNgI7zopW7"
   },
   "outputs": [],
   "source": [
    "# HYPER-PARAMETERS\n",
    "MODE = 'train'\n",
    "RUN_NAME = 'run02'\n",
    "SAVE_DIR = 'models'\n",
    "NUM_HIDDEN_UNITS = [32, 4, 32]\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save model\n",
    "model_dir = os.path.join(SAVE_DIR, RUN_NAME)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhz9xBALpHAk"
   },
   "outputs": [],
   "source": [
    "def download_data(url, filename):\n",
    "    \"\"\"\n",
    "    Download the dataset from the url\n",
    "    :param url: url of file to be downloaded\n",
    "    :param filename: filname to be saved\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "\n",
    "def load_data(filename, class_col='class', rm_nan_by_axis=0):\n",
    "    \"\"\"\n",
    "    Load the dataset from file and return X, y\n",
    "    :param filename: name of xls file\n",
    "    :param class_col: column name of class\n",
    "    :param rm_nan_by_axis: remove empty values by axis row=0, column=1\n",
    "    :return: X: features y:labels\n",
    "    \"\"\"\n",
    "    xls_file = pd.read_excel(filename, index_col=0)\n",
    "    # remove missing values by row: axis=0, column: axis=1\n",
    "    xls_file = xls_file.dropna(axis=rm_nan_by_axis)\n",
    "\n",
    "    X = xls_file[xls_file.columns[0:-4]].values\n",
    "    y = xls_file[class_col].astype('category').cat.codes.values\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL74CDBpDHL"
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "# Download the Mice Protein Expression dataset from uci\n",
    "# https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls'\n",
    "file_name = 'Data_Cortex_Nuclear.xls'\n",
    "download_data(url, file_name)\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data(file_name)\n",
    "\n",
    "num_samples, num_features = X.shape\n",
    "num_classes = np.max(y) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NP4ApWrLpunJ"
   },
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "y_onehot = onehot_encoder.fit_transform(np.expand_dims(y, axis=1))\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the model (i.e. Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7amAI6DNpyj1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "FC_1 (Dense)                 (None, 32)                2496      \n",
      "_________________________________________________________________\n",
      "FC_2 (Dense)                 (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "FC_3 (Dense)                 (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 77)                2541      \n",
      "=================================================================\n",
      "Total params: 5,329\n",
      "Trainable params: 5,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BUILD MODEL\n",
    "model = Sequential()\n",
    "model.add(Dense(NUM_HIDDEN_UNITS[0], activation='relu', name='FC_1', input_shape=(num_features,)))\n",
    "model.add(Dense(NUM_HIDDEN_UNITS[1], activation='relu', name='FC_2'))\n",
    "model.add(Dense(NUM_HIDDEN_UNITS[2], activation='relu', name='FC_3'))\n",
    "model.add(Dense(num_features, name='output'))\n",
    "model.compile(loss=keras.losses.mse,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadata for TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oUBP3ifqQm_"
   },
   "outputs": [],
   "source": [
    "def write_metadata(filename,indices, labels):\n",
    "    \"\"\"\n",
    "    Create a metadata file consisting of sample indices and labels\n",
    "    :param filename: name of the file to save on disk\n",
    "    :param shape: tensor of labels\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"Index\\tLabel\\n\")\n",
    "        for index, label in zip(indices, labels):\n",
    "            f.write(\"{}\\t{}\\n\".format(index, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmUd9eJeqQkd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jahandarjahanipour/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard\n",
    "# Save class labels to disk to color data points in TensorBoard accordingly\n",
    "index = pd.read_excel(file_name, index_col=0).index\n",
    "write_metadata(os.path.join(model_dir, 'metadata.tsv'), index, y)\n",
    "# Create tensorboard callback\n",
    "tensorboard = TensorBoard(log_dir=model_dir,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['FC_2'],\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3505
    },
    "colab_type": "code",
    "id": "sWAmVHg-qQpq",
    "outputId": "04223749-faf0-4a65-f38f-e2df0d6c4bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MODE == 'train':\n",
    "    model.fit(X_train, X_train, epochs=EPOCHS, batch_size=32, validation_split=0.2,\n",
    "              callbacks=[tensorboard])\n",
    "\n",
    "    model.save_weights(os.path.join(os.path.join(model_dir), 'wieghts.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'test':\n",
    "    model.load_weights(os.path.join(os.path.join(model_dir), 'wieghts.h5'))\n",
    "    model.layers"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
